{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries and Set Up Environment Variables\n",
    "\n",
    "First, we'll import the necessary libraries and load our NASA API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the NASA_API_KEY from the env file\n",
    "load_dotenv()\n",
    "NASA_API_KEY = os.getenv('NASA_API_KEY')\n",
    "\n",
    "# Verify API key is loaded\n",
    "if NASA_API_KEY is None:\n",
    "    raise ValueError(\"NASA_API_KEY not found in .env file\")\n",
    "print(\"API key loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Request CME data from the NASA API\n",
    "\n",
    "First, we'll fetch and process the CME (Coronal Mass Ejection) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the base URL to NASA's DONKI API\n",
    "base_url = \"https://api.nasa.gov/DONKI/\"\n",
    "\n",
    "# Set the specifier for CMEs\n",
    "specifier = \"CME\"\n",
    "\n",
    "# Search for CMEs between a begin and end date\n",
    "startDate = \"2013-05-01\"\n",
    "endDate = \"2024-05-01\"\n",
    "\n",
    "# Build URL for CME\n",
    "query_url_CME = f\"{base_url}{specifier}?startDate={startDate}&endDate={endDate}&api_key={NASA_API_KEY}\"\n",
    "\n",
    "# Make a GET request and store response\n",
    "cme_response = requests.get(query_url_CME)\n",
    "cme_json = cme_response.json()\n",
    "\n",
    "# Preview first result\n",
    "print(\"Sample CME Data:\")\n",
    "print(json.dumps(cme_json[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "cme_df = pd.DataFrame(cme_json)\n",
    "\n",
    "# Keep only required columns\n",
    "cme_df = cme_df[['activityID', 'startTime', 'linkedEvents']]\n",
    "\n",
    "# Remove rows with missing linkedEvents\n",
    "cme_df = cme_df.dropna(subset=['linkedEvents'])\n",
    "\n",
    "# Initialize empty list for expanded rows\n",
    "expanded_rows = []\n",
    "\n",
    "# Iterate through each row\n",
    "for i in cme_df.index:\n",
    "    activityID = cme_df.loc[i, 'activityID']\n",
    "    startTime = cme_df.loc[i, 'startTime']\n",
    "    linkedEvents = cme_df.loc[i, 'linkedEvents']\n",
    "    \n",
    "    # Iterate through linked events\n",
    "    for event in linkedEvents:\n",
    "        expanded_rows.append({\n",
    "            'activityID': activityID,\n",
    "            'startTime': startTime,\n",
    "            'linkedEvent': event\n",
    "        })\n",
    "\n",
    "# Create DataFrame from expanded rows\n",
    "cme_expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nExpanded CME DataFrame:\")\n",
    "print(cme_expanded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract activityID from dict\n",
    "def extract_activityID_from_dict(input_dict):\n",
    "    try:\n",
    "        return input_dict['activityID']\n",
    "    except (ValueError, TypeError) as e:\n",
    "        return None\n",
    "\n",
    "# Test the function\n",
    "print(\"\\nTesting extract_activityID_from_dict function:\")\n",
    "print(extract_activityID_from_dict(cme_df.loc[0, 'linkedEvents'][0]))\n",
    "\n",
    "# Apply function to create GST_ActivityID column\n",
    "cme_expanded_df.loc[:, 'GST_ActivityID'] = cme_expanded_df['linkedEvent'].apply(extract_activityID_from_dict)\n",
    "\n",
    "# Remove rows with missing GST_ActivityID\n",
    "cme_expanded_df = cme_expanded_df.dropna(subset=['GST_ActivityID'])\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "cme_expanded_df['GST_ActivityID'] = cme_expanded_df['GST_ActivityID'].astype(str)\n",
    "cme_expanded_df['startTime'] = pd.to_datetime(cme_expanded_df['startTime'])\n",
    "\n",
    "# Rename columns\n",
    "cme_expanded_df = cme_expanded_df.rename(columns={\n",
    "    'startTime': 'startTime_CME',\n",
    "    'activityID': 'cmeID'\n",
    "})\n",
    "\n",
    "# Drop linkedEvent column\n",
    "cme_expanded_df = cme_expanded_df.drop('linkedEvent', axis=1)\n",
    "\n",
    "# Filter for GST events\n",
    "cme_final_df = cme_expanded_df[cme_expanded_df['GST_ActivityID'].str.contains('GST')]\n",
    "\n",
    "print(\"\\nFinal CME DataFrame:\")\n",
    "print(cme_final_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(cme_final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Request GST data from the NASA API\n",
    "\n",
    "Now we'll fetch and process the GST (Geomagnetic Storm) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the specifier for GSTs\n",
    "specifier = \"GST\"\n",
    "\n",
    "# Build URL for GST\n",
    "query_url_GST = f\"{base_url}{specifier}?startDate={startDate}&endDate={endDate}&api_key={NASA_API_KEY}\"\n",
    "\n",
    "# Make a GET request and store response\n",
    "gst_response = requests.get(query_url_GST)\n",
    "gst_json = gst_response.json()\n",
    "\n",
    "# Preview first result\n",
    "print(\"Sample GST Data:\")\n",
    "print(json.dumps(gst_json[0], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "gst_df = pd.DataFrame(gst_json)\n",
    "\n",
    "# Keep only required columns\n",
    "gst_df = gst_df[['gstID', 'startTime', 'linkedEvents']]\n",
    "\n",
    "# Remove rows with missing linkedEvents\n",
    "gst_df = gst_df.dropna(subset=['linkedEvents'])\n",
    "\n",
    "# Explode linkedEvents to create separate rows\n",
    "gst_df = gst_df.explode('linkedEvents').reset_index(drop=True)\n",
    "\n",
    "# Display the first few rows after explode\n",
    "print(\"\\nGST DataFrame after explode:\")\n",
    "print(gst_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply extract_activityID_from_dict function\n",
    "gst_df.loc[:, 'CME_ActivityID'] = gst_df['linkedEvents'].apply(extract_activityID_from_dict)\n",
    "\n",
    "# Remove rows with missing CME_ActivityID\n",
    "gst_df = gst_df.dropna(subset=['CME_ActivityID'])\n",
    "\n",
    "# Convert columns to appropriate types\n",
    "gst_df['gstID'] = gst_df['gstID'].astype(str)\n",
    "gst_df['startTime'] = pd.to_datetime(gst_df['startTime'])\n",
    "\n",
    "# Rename startTime\n",
    "gst_df = gst_df.rename(columns={'startTime': 'startTime_GST'})\n",
    "\n",
    "# Drop linkedEvents\n",
    "gst_df = gst_df.drop('linkedEvents', axis=1)\n",
    "\n",
    "# Filter for CME events\n",
    "gst_final_df = gst_df[gst_df['CME_ActivityID'].str.contains('CME')]\n",
    "\n",
    "print(\"\\nFinal GST DataFrame:\")\n",
    "print(gst_final_df.info())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(gst_final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Merge and Clean the Data for Export\n",
    "\n",
    "Finally, we'll merge the CME and GST data and calculate the time differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CME and GST DataFrames\n",
    "merged_df = pd.merge(\n",
    "    gst_final_df,\n",
    "    cme_final_df,\n",
    "    left_on=['gstID', 'CME_ActivityID'],\n",
    "    right_on=['GST_ActivityID', 'cmeID']\n",
    ")\n",
    "\n",
    "# Verify row counts\n",
    "print(\"Row counts:\")\n",
    "print(f\"CME DataFrame: {len(cme_final_df)}\")\n",
    "print(f\"GST DataFrame: {len(gst_final_df)}\")\n",
    "print(f\"Merged DataFrame: {len(merged_df)}\")\n",
    "\n",
    "# Calculate time difference in hours\n",
    "merged_df['timeDiff'] = (merged_df['startTime_GST'] - merged_df['startTime_CME']).dt.total_seconds() / 3600\n",
    "\n",
    "# Show time difference statistics\n",
    "print(\"\\nTime Difference Statistics (hours):\")\n",
    "print(merged_df['timeDiff'].describe())\n",
    "\n",
    "# Display first few rows of final dataset\n",
    "print(\"\\nFirst few rows of merged data:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Export to CSV\n",
    "output_path = \"6-output/collected_data.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nData exported to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
